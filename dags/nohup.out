  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2023-11-19 07:41:07 +0000] [4678] [INFO] Starting gunicorn 20.1.0
[2023-11-19 07:41:07 +0000] [4678] [ERROR] Connection in use: ('::', 8793)
[2023-11-19 07:41:07 +0000] [4678] [ERROR] Retrying in 1 second.
[[34m2023-11-19 07:41:07,629[0m] {[34mscheduler_job.py:[0m714} INFO[0m - Starting the scheduler[0m
[[34m2023-11-19 07:41:07,629[0m] {[34mscheduler_job.py:[0m719} INFO[0m - Processing each file at most -1 times[0m
[[34m2023-11-19 07:41:07,640[0m] {[34mexecutor_loader.py:[0m107} INFO[0m - Loaded executor: LocalExecutor[0m
[[34m2023-11-19 07:41:07,808[0m] {[34mmanager.py:[0m163} INFO[0m - Launched DagFileProcessorManager with pid: 4779[0m
[[34m2023-11-19 07:41:07,810[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 07:41:07,844[0m] {[34mscheduler_job.py:[0m1422} INFO[0m - Marked 2 SchedulerJob instances as failed[0m
[[34m2023-11-19 07:41:07,878[0m] {[34msettings.py:[0m58} INFO[0m - Configured default timezone Timezone('Asia/Jakarta')[0m
[2023-11-19 07:41:08 +0000] [4678] [ERROR] Connection in use: ('::', 8793)
[2023-11-19 07:41:08 +0000] [4678] [ERROR] Retrying in 1 second.
[2023-11-19 07:41:09 +0000] [4678] [ERROR] Connection in use: ('::', 8793)
[2023-11-19 07:41:09 +0000] [4678] [ERROR] Retrying in 1 second.
[2023-11-19 07:41:10 +0000] [4678] [ERROR] Connection in use: ('::', 8793)
[2023-11-19 07:41:10 +0000] [4678] [ERROR] Retrying in 1 second.
[2023-11-19 07:41:11 +0000] [4678] [ERROR] Connection in use: ('::', 8793)
[2023-11-19 07:41:11 +0000] [4678] [ERROR] Retrying in 1 second.
[2023-11-19 07:41:12 +0000] [4678] [ERROR] Can't connect to ('::', 8793)
[[34m2023-11-19 07:41:20,177[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-19T07:41:19.355879+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task manual__2023-11-19T07:41:19.355879+00:00 [scheduled]>[0m
[[34m2023-11-19 07:41:20,177[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 07:41:20,177[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 07:41:20,177[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-19T07:41:19.355879+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task manual__2023-11-19T07:41:19.355879+00:00 [scheduled]>[0m
[[34m2023-11-19 07:41:20,180[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='manual__2023-11-19T07:41:19.355879+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 07:41:20,180[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'manual__2023-11-19T07:41:19.355879+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:41:20,181[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='manual__2023-11-19T07:41:19.355879+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 07:41:20,181[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'manual__2023-11-19T07:41:19.355879+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:41:20,188[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'manual__2023-11-19T07:41:19.355879+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:41:20,191[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'manual__2023-11-19T07:41:19.355879+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:41:20,243[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:41:20,243[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:41:20,841[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-19T07:41:19.355879+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:41:20,899[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task manual__2023-11-19T07:41:19.355879+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:41:22,415[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task manual__2023-11-19T07:41:19.355879+00:00 [scheduled]>[0m
[[34m2023-11-19 07:41:22,415[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 07:41:22,415[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task manual__2023-11-19T07:41:19.355879+00:00 [scheduled]>[0m
[[34m2023-11-19 07:41:22,419[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='manual__2023-11-19T07:41:19.355879+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 07:41:22,419[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'manual__2023-11-19T07:41:19.355879+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:41:22,435[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'manual__2023-11-19T07:41:19.355879+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:41:22,435[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=manual__2023-11-19T07:41:19.355879+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:41:22,444[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=manual__2023-11-19T07:41:19.355879+00:00, map_index=-1, run_start_date=2023-11-19 07:41:20.910973+00:00, run_end_date=2023-11-19 07:41:21.672634+00:00, run_duration=0.761661, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1204, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 07:41:20.178242+00:00, queued_by_job_id=1203, pid=4846[0m
[[34m2023-11-19 07:41:22,509[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:41:23,089[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task manual__2023-11-19T07:41:19.355879+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:41:24,158[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=manual__2023-11-19T07:41:19.355879+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:41:24,163[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=manual__2023-11-19T07:41:19.355879+00:00, map_index=-1, run_start_date=2023-11-19 07:41:23.147911+00:00, run_end_date=2023-11-19 07:41:23.385027+00:00, run_duration=0.237116, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=1206, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 07:41:22.416259+00:00, queued_by_job_id=1203, pid=4963[0m
[[34m2023-11-19 07:42:03,697[0m] {[34mdagrun.py:[0m585} ERROR[0m - Marking run <DagRun party_animals @ 2023-11-19 07:41:19.355879+00:00: manual__2023-11-19T07:41:19.355879+00:00, state:running, queued_at: 2023-11-19 07:41:19.363698+00:00. externally triggered: True> failed[0m
[[34m2023-11-19 07:42:03,698[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 07:41:19.355879+00:00, run_id=manual__2023-11-19T07:41:19.355879+00:00, run_start_date=2023-11-19 07:41:20.114330+00:00, run_end_date=2023-11-19 07:42:03.698266+00:00, run_duration=43.583936, state=failed, external_trigger=True, run_type=manual, data_interval_start=2023-11-17 17:00:00+00:00, data_interval_end=2023-11-18 17:00:00+00:00, dag_hash=35ffd8296b4df92771354991ca2cb2de[0m
[[34m2023-11-19 07:42:03,704[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-18T17:00:00+00:00, run_after=2023-11-19T17:00:00+00:00[0m
[[34m2023-11-19 07:42:03,730[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=manual__2023-11-19T07:41:19.355879+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:42:03,735[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=manual__2023-11-19T07:41:19.355879+00:00, map_index=-1, run_start_date=2023-11-19 07:41:20.966682+00:00, run_end_date=2023-11-19 07:42:02.812735+00:00, run_duration=41.846053, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=1205, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 07:41:20.178242+00:00, queued_by_job_id=1203, pid=4848[0m
[[34m2023-11-19 07:46:07,932[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 07:46:24,945[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:46:24,946[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 07:46:24,946[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 07:46:24,946[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:46:24,948[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='manual__2023-11-19T07:46:24.254351+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 07:46:24,948[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:46:24,949[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='manual__2023-11-19T07:46:24.254351+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 07:46:24,949[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:46:24,959[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:46:24,962[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:46:25,047[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:46:25,085[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:46:25,657[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task manual__2023-11-19T07:46:24.254351+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:46:25,729[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-19T07:46:24.254351+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:46:26,929[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:46:26,929[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 07:46:26,929[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:46:26,932[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='manual__2023-11-19T07:46:24.254351+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 07:46:26,932[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:46:26,947[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=manual__2023-11-19T07:46:24.254351+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:46:26,948[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:46:26,953[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=manual__2023-11-19T07:46:24.254351+00:00, map_index=-1, run_start_date=2023-11-19 07:46:25.795685+00:00, run_end_date=2023-11-19 07:46:26.585410+00:00, run_duration=0.789725, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1208, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 07:46:24.946653+00:00, queued_by_job_id=1203, pid=5229[0m
[[34m2023-11-19 07:46:27,020[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:46:27,617[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task manual__2023-11-19T07:46:24.254351+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:46:28,215[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=manual__2023-11-19T07:46:24.254351+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:46:28,219[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=manual__2023-11-19T07:46:24.254351+00:00, map_index=-1, run_start_date=2023-11-19 07:46:27.674753+00:00, run_end_date=2023-11-19 07:46:27.953101+00:00, run_duration=0.278348, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1209, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 07:46:26.930213+00:00, queued_by_job_id=1203, pid=5348[0m
[[34m2023-11-19 07:47:06,850[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:47:06,850[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 07:47:06,850[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:47:06,852[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='manual__2023-11-19T07:46:24.254351+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 07:47:06,853[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:06,861[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:06,863[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=manual__2023-11-19T07:46:24.254351+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:47:06,867[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=manual__2023-11-19T07:46:24.254351+00:00, map_index=-1, run_start_date=2023-11-19 07:46:25.727269+00:00, run_end_date=2023-11-19 07:47:06.448740+00:00, run_duration=40.721471, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1207, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 07:46:24.946653+00:00, queued_by_job_id=1203, pid=5226[0m
[[34m2023-11-19 07:47:06,906[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:47:07,445[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task manual__2023-11-19T07:46:24.254351+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:47:08,172[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:47:08,173[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 07:47:08,173[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:47:08,175[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='manual__2023-11-19T07:46:24.254351+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-19 07:47:08,175[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:08,184[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:08,188[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=manual__2023-11-19T07:46:24.254351+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:47:08,193[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=manual__2023-11-19T07:46:24.254351+00:00, map_index=-1, run_start_date=2023-11-19 07:47:07.503178+00:00, run_end_date=2023-11-19 07:47:07.897069+00:00, run_duration=0.393891, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1210, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 07:47:06.851165+00:00, queued_by_job_id=1203, pid=5430[0m
[[34m2023-11-19 07:47:08,283[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:47:08,801[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task manual__2023-11-19T07:46:24.254351+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:47:11,156[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:47:11,157[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 07:47:11,159[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 07:47:11,159[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:47:11,163[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='manual__2023-11-19T07:46:24.254351+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 07:47:11,163[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:11,163[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='manual__2023-11-19T07:46:24.254351+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 07:47:11,163[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:11,204[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:11,209[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:11,215[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=manual__2023-11-19T07:46:24.254351+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:47:11,219[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=manual__2023-11-19T07:46:24.254351+00:00, map_index=-1, run_start_date=2023-11-19 07:47:08.878083+00:00, run_end_date=2023-11-19 07:47:09.850273+00:00, run_duration=0.97219, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1211, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-19 07:47:08.173715+00:00, queued_by_job_id=1203, pid=5448[0m
[[34m2023-11-19 07:47:11,313[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:47:11,358[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:47:12,012[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task manual__2023-11-19T07:46:24.254351+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:47:12,087[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task manual__2023-11-19T07:46:24.254351+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:47:14,039[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:47:14,039[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 07:47:14,039[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task manual__2023-11-19T07:46:24.254351+00:00 [scheduled]>[0m
[[34m2023-11-19 07:47:14,041[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='manual__2023-11-19T07:46:24.254351+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-19 07:47:14,041[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:14,080[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'manual__2023-11-19T07:46:24.254351+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 07:47:14,083[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=manual__2023-11-19T07:46:24.254351+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:47:14,086[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=manual__2023-11-19T07:46:24.254351+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:47:14,092[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=manual__2023-11-19T07:46:24.254351+00:00, map_index=-1, run_start_date=2023-11-19 07:47:12.105432+00:00, run_end_date=2023-11-19 07:47:12.776532+00:00, run_duration=0.6711, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1212, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 07:47:11.159842+00:00, queued_by_job_id=1203, pid=5478[0m
[[34m2023-11-19 07:47:14,093[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=manual__2023-11-19T07:46:24.254351+00:00, map_index=-1, run_start_date=2023-11-19 07:47:12.233232+00:00, run_end_date=2023-11-19 07:47:12.863075+00:00, run_duration=0.629843, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1213, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 07:47:11.159842+00:00, queued_by_job_id=1203, pid=5480[0m
[[34m2023-11-19 07:47:14,789[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 07:47:15,355[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task manual__2023-11-19T07:46:24.254351+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 07:47:17,464[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-19 07:46:24.254351+00:00: manual__2023-11-19T07:46:24.254351+00:00, state:running, queued_at: 2023-11-19 07:46:24.262934+00:00. externally triggered: True> successful[0m
[[34m2023-11-19 07:47:17,464[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 07:46:24.254351+00:00, run_id=manual__2023-11-19T07:46:24.254351+00:00, run_start_date=2023-11-19 07:46:24.882476+00:00, run_end_date=2023-11-19 07:47:17.464798+00:00, run_duration=52.582322, state=success, external_trigger=True, run_type=manual, data_interval_start=2023-11-17 17:00:00+00:00, data_interval_end=2023-11-18 17:00:00+00:00, dag_hash=35ffd8296b4df92771354991ca2cb2de[0m
[[34m2023-11-19 07:47:17,471[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-18T17:00:00+00:00, run_after=2023-11-19T17:00:00+00:00[0m
[[34m2023-11-19 07:47:17,509[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=manual__2023-11-19T07:46:24.254351+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 07:47:17,513[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=manual__2023-11-19T07:46:24.254351+00:00, map_index=-1, run_start_date=2023-11-19 07:47:15.559869+00:00, run_end_date=2023-11-19 07:47:16.392900+00:00, run_duration=0.833031, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1214, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-19 07:47:14.040062+00:00, queued_by_job_id=1203, pid=5507[0m
[[34m2023-11-19 07:51:07,982[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 07:56:08,029[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:01:08,105[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:06:08,156[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:11:08,216[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:16:08,271[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:21:08,319[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:26:08,363[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:31:08,433[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:36:08,480[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:41:08,526[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:46:08,573[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:51:08,619[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 08:56:08,668[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:01:08,732[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:06:08,776[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:11:08,834[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:16:08,880[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:21:08,925[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:26:08,975[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:31:09,021[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:36:09,070[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:41:09,130[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:46:09,181[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:51:09,228[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 09:56:09,274[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:01:09,322[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:06:09,369[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:11:09,424[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:16:09,471[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:21:09,531[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:26:09,579[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:31:09,626[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:36:09,671[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:41:09,733[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:46:09,781[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:51:09,826[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 10:56:09,877[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:01:09,920[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:06:09,969[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:11:10,027[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:16:10,075[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:21:10,121[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:26:10,175[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:31:10,220[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:36:10,267[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:41:10,330[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:46:10,377[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:51:10,421[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 11:56:10,467[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:01:10,513[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:06:10,561[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:11:10,608[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:16:10,660[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:21:10,707[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:26:10,756[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:31:10,804[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:36:10,856[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:41:10,903[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:46:10,948[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:51:11,001[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 12:56:11,047[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:01:11,097[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:06:11,148[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:11:11,208[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:16:11,258[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:21:11,302[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:26:11,349[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:31:11,398[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:36:11,445[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:41:11,493[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:46:11,547[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:51:11,591[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 13:56:11,636[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:01:11,684[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:06:11,737[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:11:11,783[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:16:11,834[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:21:11,889[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:26:11,959[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:31:12,011[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:36:12,061[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:41:12,106[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:46:12,152[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:51:12,197[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 14:56:12,225[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:01:12,278[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:06:12,324[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:11:12,376[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:16:12,422[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:21:12,468[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:26:12,513[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:31:12,566[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:36:12,622[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:41:12,667[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:46:12,715[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:51:12,763[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 15:56:12,813[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:01:12,860[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:06:12,909[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:11:12,963[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:16:13,018[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:21:13,071[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:26:13,120[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:31:13,169[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:36:13,214[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:41:13,261[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:46:13,310[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:51:13,360[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 16:56:13,405[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:01:13,451[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:06:13,497[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:11:13,555[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:16:13,601[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:21:13,651[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:26:13,704[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:31:13,751[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:36:13,797[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:41:13,850[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:46:13,896[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:51:13,944[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 17:56:13,992[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:00:00,337[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T18:00:00+00:00, run_after=2023-11-19T19:00:00+00:00[0m
[[34m2023-11-19 18:00:00,582[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:00,582[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 18:00:00,582[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 18:00:00,582[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:00,584[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='scheduled__2023-11-19T17:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 18:00:00,585[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:00,585[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='scheduled__2023-11-19T17:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 18:00:00,585[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:00,639[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:00,643[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:00,815[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 18:00:00,820[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 18:00:01,341[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T17:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 18:00:01,344[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T17:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 18:00:04,859[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:04,860[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 18:00:04,860[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:04,862[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='scheduled__2023-11-19T17:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 18:00:04,863[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:04,871[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:04,876[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=scheduled__2023-11-19T17:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 18:00:04,882[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=scheduled__2023-11-19T17:00:00+00:00, map_index=-1, run_start_date=2023-11-19 18:00:01.524267+00:00, run_end_date=2023-11-19 18:00:03.052937+00:00, run_duration=1.52867, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1215, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 18:00:00.583170+00:00, queued_by_job_id=1203, pid=37672[0m
[[34m2023-11-19 18:00:04,968[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 18:00:05,708[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T17:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 18:00:06,861[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=scheduled__2023-11-19T17:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 18:00:06,865[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=scheduled__2023-11-19T17:00:00+00:00, map_index=-1, run_start_date=2023-11-19 18:00:05.770172+00:00, run_end_date=2023-11-19 18:00:06.055071+00:00, run_duration=0.284899, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1217, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 18:00:04.861060+00:00, queued_by_job_id=1203, pid=37799[0m
[[34m2023-11-19 18:00:44,651[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:44,651[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 18:00:44,651[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:44,653[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='scheduled__2023-11-19T17:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 18:00:44,654[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:44,661[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:44,663[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=scheduled__2023-11-19T17:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 18:00:44,667[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=scheduled__2023-11-19T17:00:00+00:00, map_index=-1, run_start_date=2023-11-19 18:00:01.811215+00:00, run_end_date=2023-11-19 18:00:43.837794+00:00, run_duration=42.026579, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1216, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 18:00:00.583170+00:00, queued_by_job_id=1203, pid=37678[0m
[[34m2023-11-19 18:00:44,707[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 18:00:45,225[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T17:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 18:00:45,793[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:45,793[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 18:00:45,793[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:45,795[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='scheduled__2023-11-19T17:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-19 18:00:45,795[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:45,802[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:45,877[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=scheduled__2023-11-19T17:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 18:00:45,881[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=scheduled__2023-11-19T17:00:00+00:00, map_index=-1, run_start_date=2023-11-19 18:00:45.294476+00:00, run_end_date=2023-11-19 18:00:45.676848+00:00, run_duration=0.382372, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1218, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 18:00:44.652255+00:00, queued_by_job_id=1203, pid=37864[0m
[[34m2023-11-19 18:00:45,887[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 18:00:46,385[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T17:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 18:00:47,485[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:47,486[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 18:00:47,486[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 18:00:47,486[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:47,488[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='scheduled__2023-11-19T17:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 18:00:47,488[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:47,488[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='scheduled__2023-11-19T17:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 18:00:47,488[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:47,495[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:47,499[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=scheduled__2023-11-19T17:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 18:00:47,499[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:47,505[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=scheduled__2023-11-19T17:00:00+00:00, map_index=-1, run_start_date=2023-11-19 18:00:46.442923+00:00, run_end_date=2023-11-19 18:00:47.288618+00:00, run_duration=0.845695, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1219, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-19 18:00:45.794093+00:00, queued_by_job_id=1203, pid=37882[0m
[[34m2023-11-19 18:00:47,556[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 18:00:47,558[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 18:00:48,121[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T17:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 18:00:48,124[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task scheduled__2023-11-19T17:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 18:00:49,742[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:49,742[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 18:00:49,742[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T17:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 18:00:49,744[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='scheduled__2023-11-19T17:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-19 18:00:49,744[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:49,751[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 18:00:49,755[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=scheduled__2023-11-19T17:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 18:00:49,755[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=scheduled__2023-11-19T17:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 18:00:49,760[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=scheduled__2023-11-19T17:00:00+00:00, map_index=-1, run_start_date=2023-11-19 18:00:48.184693+00:00, run_end_date=2023-11-19 18:00:48.668536+00:00, run_duration=0.483843, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1220, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 18:00:47.486837+00:00, queued_by_job_id=1203, pid=37909[0m
[[34m2023-11-19 18:00:49,760[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=scheduled__2023-11-19T17:00:00+00:00, map_index=-1, run_start_date=2023-11-19 18:00:48.200660+00:00, run_end_date=2023-11-19 18:00:48.770318+00:00, run_duration=0.569658, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1221, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 18:00:47.486837+00:00, queued_by_job_id=1203, pid=37911[0m
[[34m2023-11-19 18:00:49,794[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 18:00:50,336[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T17:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 18:00:51,445[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-19 17:00:00+00:00: scheduled__2023-11-19T17:00:00+00:00, state:running, queued_at: 2023-11-19 18:00:00.321631+00:00. externally triggered: False> successful[0m
[[34m2023-11-19 18:00:51,445[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 17:00:00+00:00, run_id=scheduled__2023-11-19T17:00:00+00:00, run_start_date=2023-11-19 18:00:00.455596+00:00, run_end_date=2023-11-19 18:00:51.445307+00:00, run_duration=50.989711, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-11-19 17:00:00+00:00, data_interval_end=2023-11-19 18:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-19 18:00:51,453[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T18:00:00+00:00, run_after=2023-11-19T19:00:00+00:00[0m
[[34m2023-11-19 18:00:51,479[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=scheduled__2023-11-19T17:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 18:00:51,482[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=scheduled__2023-11-19T17:00:00+00:00, map_index=-1, run_start_date=2023-11-19 18:00:50.408111+00:00, run_end_date=2023-11-19 18:00:50.812537+00:00, run_duration=0.404426, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1222, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-19 18:00:49.742772+00:00, queued_by_job_id=1203, pid=37949[0m
[[34m2023-11-19 18:01:14,037[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:06:14,085[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:11:14,131[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:16:14,179[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:21:14,224[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:26:14,270[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:31:14,327[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:36:14,382[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:41:14,428[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:46:14,477[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:51:14,529[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 18:56:14,575[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:00:00,838[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T19:00:00+00:00, run_after=2023-11-19T20:00:00+00:00[0m
[[34m2023-11-19 19:00:00,893[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:00,893[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 19:00:00,893[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 19:00:00,893[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:00,895[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='scheduled__2023-11-19T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 19:00:00,895[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:00,895[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='scheduled__2023-11-19T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 19:00:00,895[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:00,902[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:00,904[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:00,955[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 19:00:00,964[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 19:00:01,526[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T18:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 19:00:01,530[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T18:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 19:00:02,785[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:02,786[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 19:00:02,786[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:02,788[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='scheduled__2023-11-19T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 19:00:02,788[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:02,798[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=scheduled__2023-11-19T18:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 19:00:02,799[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:02,804[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=scheduled__2023-11-19T18:00:00+00:00, map_index=-1, run_start_date=2023-11-19 19:00:01.608661+00:00, run_end_date=2023-11-19 19:00:02.560105+00:00, run_duration=0.951444, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1224, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 19:00:00.893819+00:00, queued_by_job_id=1203, pid=40083[0m
[[34m2023-11-19 19:00:02,858[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 19:00:03,416[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T18:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 19:00:03,961[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=scheduled__2023-11-19T18:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 19:00:03,965[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=scheduled__2023-11-19T18:00:00+00:00, map_index=-1, run_start_date=2023-11-19 19:00:03.490783+00:00, run_end_date=2023-11-19 19:00:03.771259+00:00, run_duration=0.280476, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1225, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 19:00:02.786664+00:00, queued_by_job_id=1203, pid=40206[0m
[[34m2023-11-19 19:00:43,029[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:43,029[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 19:00:43,029[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:43,031[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='scheduled__2023-11-19T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 19:00:43,032[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:43,038[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:43,043[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=scheduled__2023-11-19T18:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 19:00:43,047[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=scheduled__2023-11-19T18:00:00+00:00, map_index=-1, run_start_date=2023-11-19 19:00:01.603245+00:00, run_end_date=2023-11-19 19:00:42.520209+00:00, run_duration=40.916964, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1223, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 19:00:00.893819+00:00, queued_by_job_id=1203, pid=40082[0m
[[34m2023-11-19 19:00:43,097[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 19:00:43,665[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T18:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 19:00:44,525[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:44,525[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 19:00:44,525[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:44,527[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='scheduled__2023-11-19T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-19 19:00:44,527[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:44,536[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:44,538[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=scheduled__2023-11-19T18:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 19:00:44,542[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=scheduled__2023-11-19T18:00:00+00:00, map_index=-1, run_start_date=2023-11-19 19:00:43.738039+00:00, run_end_date=2023-11-19 19:00:44.122191+00:00, run_duration=0.384152, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1226, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 19:00:43.030477+00:00, queued_by_job_id=1203, pid=40280[0m
[[34m2023-11-19 19:00:44,586[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 19:00:45,102[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T18:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 19:00:46,312[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:46,312[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 19:00:46,312[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 19:00:46,312[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:46,314[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='scheduled__2023-11-19T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 19:00:46,314[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:46,314[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='scheduled__2023-11-19T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 19:00:46,314[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:46,321[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:46,327[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=scheduled__2023-11-19T18:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 19:00:46,327[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:46,341[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=scheduled__2023-11-19T18:00:00+00:00, map_index=-1, run_start_date=2023-11-19 19:00:45.172431+00:00, run_end_date=2023-11-19 19:00:45.938192+00:00, run_duration=0.765761, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1227, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-19 19:00:44.525688+00:00, queued_by_job_id=1203, pid=40298[0m
[[34m2023-11-19 19:00:46,377[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 19:00:46,409[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 19:00:47,114[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T18:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 19:00:47,165[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task scheduled__2023-11-19T18:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 19:00:48,074[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:48,074[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 19:00:48,074[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T18:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 19:00:48,076[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='scheduled__2023-11-19T18:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-19 19:00:48,077[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:48,084[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 19:00:48,086[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=scheduled__2023-11-19T18:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 19:00:48,087[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=scheduled__2023-11-19T18:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 19:00:48,091[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=scheduled__2023-11-19T18:00:00+00:00, map_index=-1, run_start_date=2023-11-19 19:00:47.234270+00:00, run_end_date=2023-11-19 19:00:47.580779+00:00, run_duration=0.346509, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1229, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 19:00:46.312990+00:00, queued_by_job_id=1203, pid=40331[0m
[[34m2023-11-19 19:00:48,091[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=scheduled__2023-11-19T18:00:00+00:00, map_index=-1, run_start_date=2023-11-19 19:00:47.187141+00:00, run_end_date=2023-11-19 19:00:47.527652+00:00, run_duration=0.340511, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1228, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 19:00:46.312990+00:00, queued_by_job_id=1203, pid=40329[0m
[[34m2023-11-19 19:00:48,133[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 19:00:48,679[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T18:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 19:00:49,565[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-19 18:00:00+00:00: scheduled__2023-11-19T18:00:00+00:00, state:running, queued_at: 2023-11-19 19:00:00.830370+00:00. externally triggered: False> successful[0m
[[34m2023-11-19 19:00:49,565[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 18:00:00+00:00, run_id=scheduled__2023-11-19T18:00:00+00:00, run_start_date=2023-11-19 19:00:00.854545+00:00, run_end_date=2023-11-19 19:00:49.565361+00:00, run_duration=48.710816, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-11-19 18:00:00+00:00, data_interval_end=2023-11-19 19:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-19 19:00:49,570[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T19:00:00+00:00, run_after=2023-11-19T20:00:00+00:00[0m
[[34m2023-11-19 19:00:49,591[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=scheduled__2023-11-19T18:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 19:00:49,595[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=scheduled__2023-11-19T18:00:00+00:00, map_index=-1, run_start_date=2023-11-19 19:00:48.736217+00:00, run_end_date=2023-11-19 19:00:49.134895+00:00, run_duration=0.398678, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1230, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-19 19:00:48.075138+00:00, queued_by_job_id=1203, pid=40358[0m
[[34m2023-11-19 19:01:14,633[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:06:14,680[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:11:14,742[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:16:14,793[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:21:14,846[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:26:14,898[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:31:14,948[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:36:14,997[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:41:15,066[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:46:15,117[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:51:15,161[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 19:56:15,208[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:00:00,042[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T20:00:00+00:00, run_after=2023-11-19T21:00:00+00:00[0m
[[34m2023-11-19 20:00:00,161[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:00,161[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 20:00:00,161[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 20:00:00,162[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:00,163[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='scheduled__2023-11-19T19:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 20:00:00,164[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:00,164[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='scheduled__2023-11-19T19:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 20:00:00,164[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:00,182[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:00,188[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:00,276[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 20:00:00,287[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 20:00:00,860[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T19:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 20:00:00,883[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T19:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 20:00:02,159[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:02,159[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 20:00:02,159[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:02,161[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='scheduled__2023-11-19T19:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 20:00:02,162[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:02,176[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:02,181[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=scheduled__2023-11-19T19:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 20:00:02,186[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=scheduled__2023-11-19T19:00:00+00:00, map_index=-1, run_start_date=2023-11-19 20:00:00.954576+00:00, run_end_date=2023-11-19 20:00:01.803568+00:00, run_duration=0.848992, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1232, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 20:00:00.162438+00:00, queued_by_job_id=1203, pid=42436[0m
[[34m2023-11-19 20:00:02,231[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 20:00:02,766[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T19:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 20:00:03,370[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=scheduled__2023-11-19T19:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 20:00:03,378[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=scheduled__2023-11-19T19:00:00+00:00, map_index=-1, run_start_date=2023-11-19 20:00:02.832367+00:00, run_end_date=2023-11-19 20:00:03.139010+00:00, run_duration=0.306643, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1233, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 20:00:02.160077+00:00, queued_by_job_id=1203, pid=42555[0m
[[34m2023-11-19 20:00:42,474[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:42,474[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 20:00:42,475[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:42,476[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='scheduled__2023-11-19T19:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 20:00:42,477[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:42,499[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:42,503[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=scheduled__2023-11-19T19:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 20:00:42,507[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=scheduled__2023-11-19T19:00:00+00:00, map_index=-1, run_start_date=2023-11-19 20:00:00.919925+00:00, run_end_date=2023-11-19 20:00:41.943002+00:00, run_duration=41.023077, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1231, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 20:00:00.162438+00:00, queued_by_job_id=1203, pid=42434[0m
[[34m2023-11-19 20:00:42,545[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 20:00:43,073[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T19:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 20:00:44,226[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:44,226[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 20:00:44,227[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:44,228[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='scheduled__2023-11-19T19:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-19 20:00:44,228[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:44,235[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=scheduled__2023-11-19T19:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 20:00:44,235[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:44,239[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=scheduled__2023-11-19T19:00:00+00:00, map_index=-1, run_start_date=2023-11-19 20:00:43.143015+00:00, run_end_date=2023-11-19 20:00:43.504503+00:00, run_duration=0.361488, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1234, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 20:00:42.475470+00:00, queued_by_job_id=1203, pid=42636[0m
[[34m2023-11-19 20:00:44,275[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 20:00:44,808[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T19:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 20:00:45,839[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:45,840[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 20:00:45,840[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 20:00:45,840[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:45,842[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='scheduled__2023-11-19T19:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 20:00:45,842[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:45,842[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='scheduled__2023-11-19T19:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 20:00:45,842[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:45,849[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:45,851[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=scheduled__2023-11-19T19:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 20:00:45,852[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:45,859[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=scheduled__2023-11-19T19:00:00+00:00, map_index=-1, run_start_date=2023-11-19 20:00:44.871419+00:00, run_end_date=2023-11-19 20:00:45.598505+00:00, run_duration=0.727086, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1235, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-19 20:00:44.227333+00:00, queued_by_job_id=1203, pid=42654[0m
[[34m2023-11-19 20:00:45,898[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 20:00:45,930[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 20:00:46,444[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T19:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 20:00:46,481[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task scheduled__2023-11-19T19:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 20:00:47,018[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:47,018[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 20:00:47,018[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T19:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 20:00:47,020[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='scheduled__2023-11-19T19:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-19 20:00:47,020[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:47,027[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 20:00:47,031[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=scheduled__2023-11-19T19:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 20:00:47,031[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=scheduled__2023-11-19T19:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 20:00:47,035[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=scheduled__2023-11-19T19:00:00+00:00, map_index=-1, run_start_date=2023-11-19 20:00:46.513522+00:00, run_end_date=2023-11-19 20:00:46.805973+00:00, run_duration=0.292451, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1236, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 20:00:45.840752+00:00, queued_by_job_id=1203, pid=42681[0m
[[34m2023-11-19 20:00:47,035[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=scheduled__2023-11-19T19:00:00+00:00, map_index=-1, run_start_date=2023-11-19 20:00:46.545680+00:00, run_end_date=2023-11-19 20:00:46.872012+00:00, run_duration=0.326332, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1237, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 20:00:45.840752+00:00, queued_by_job_id=1203, pid=42683[0m
[[34m2023-11-19 20:00:47,072[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 20:00:47,557[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T19:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 20:00:48,135[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-19 19:00:00+00:00: scheduled__2023-11-19T19:00:00+00:00, state:running, queued_at: 2023-11-19 20:00:00.030242+00:00. externally triggered: False> successful[0m
[[34m2023-11-19 20:00:48,136[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 19:00:00+00:00, run_id=scheduled__2023-11-19T19:00:00+00:00, run_start_date=2023-11-19 20:00:00.063627+00:00, run_end_date=2023-11-19 20:00:48.136018+00:00, run_duration=48.072391, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-11-19 19:00:00+00:00, data_interval_end=2023-11-19 20:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-19 20:00:48,140[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T20:00:00+00:00, run_after=2023-11-19T21:00:00+00:00[0m
[[34m2023-11-19 20:00:48,161[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=scheduled__2023-11-19T19:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 20:00:48,173[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=scheduled__2023-11-19T19:00:00+00:00, map_index=-1, run_start_date=2023-11-19 20:00:47.614025+00:00, run_end_date=2023-11-19 20:00:48.013414+00:00, run_duration=0.399389, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1238, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-19 20:00:47.019254+00:00, queued_by_job_id=1203, pid=42710[0m
[[34m2023-11-19 20:01:15,256[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:06:15,309[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:11:15,356[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:16:15,403[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:21:15,454[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:26:15,505[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:31:15,558[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:36:15,607[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:41:15,657[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:46:15,704[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:51:15,753[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 20:56:15,802[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:00:00,604[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T21:00:00+00:00, run_after=2023-11-19T22:00:00+00:00[0m
[[34m2023-11-19 21:00:00,662[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:00,662[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 21:00:00,662[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 21:00:00,662[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:00,664[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='scheduled__2023-11-19T20:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 21:00:00,664[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:00,664[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='scheduled__2023-11-19T20:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 21:00:00,665[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:00,677[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:00,679[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:00,726[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 21:00:00,734[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 21:00:01,334[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T20:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 21:00:01,372[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T20:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 21:00:03,810[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:03,810[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 21:00:03,810[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:03,812[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='scheduled__2023-11-19T20:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 21:00:03,812[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:03,819[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:03,819[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=scheduled__2023-11-19T20:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 21:00:03,823[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=scheduled__2023-11-19T20:00:00+00:00, map_index=-1, run_start_date=2023-11-19 21:00:01.421364+00:00, run_end_date=2023-11-19 21:00:03.091281+00:00, run_duration=1.669917, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1239, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 21:00:00.663253+00:00, queued_by_job_id=1203, pid=44827[0m
[[34m2023-11-19 21:00:03,863[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 21:00:04,590[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T20:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 21:00:06,029[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=scheduled__2023-11-19T20:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 21:00:06,033[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=scheduled__2023-11-19T20:00:00+00:00, map_index=-1, run_start_date=2023-11-19 21:00:04.665703+00:00, run_end_date=2023-11-19 21:00:04.940462+00:00, run_duration=0.274759, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1241, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 21:00:03.811087+00:00, queued_by_job_id=1203, pid=44954[0m
[[34m2023-11-19 21:00:44,230[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:44,230[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 21:00:44,231[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:44,232[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='scheduled__2023-11-19T20:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 21:00:44,232[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:44,239[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:44,243[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=scheduled__2023-11-19T20:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 21:00:44,247[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=scheduled__2023-11-19T20:00:00+00:00, map_index=-1, run_start_date=2023-11-19 21:00:01.478392+00:00, run_end_date=2023-11-19 21:00:43.893194+00:00, run_duration=42.414802, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1240, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 21:00:00.663253+00:00, queued_by_job_id=1203, pid=44829[0m
[[34m2023-11-19 21:00:44,283[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 21:00:44,799[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T20:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 21:00:45,715[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:45,716[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 21:00:45,716[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:45,717[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='scheduled__2023-11-19T20:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-19 21:00:45,717[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:45,725[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:45,727[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=scheduled__2023-11-19T20:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 21:00:45,731[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=scheduled__2023-11-19T20:00:00+00:00, map_index=-1, run_start_date=2023-11-19 21:00:44.863057+00:00, run_end_date=2023-11-19 21:00:45.222328+00:00, run_duration=0.359271, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1242, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 21:00:44.231401+00:00, queued_by_job_id=1203, pid=45020[0m
[[34m2023-11-19 21:00:45,769[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 21:00:46,290[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T20:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 21:00:47,523[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:47,523[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 21:00:47,523[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 21:00:47,523[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:47,525[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='scheduled__2023-11-19T20:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 21:00:47,525[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:47,526[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='scheduled__2023-11-19T20:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 21:00:47,526[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:47,532[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:47,535[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=scheduled__2023-11-19T20:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 21:00:47,535[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:47,539[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=scheduled__2023-11-19T20:00:00+00:00, map_index=-1, run_start_date=2023-11-19 21:00:46.346632+00:00, run_end_date=2023-11-19 21:00:47.088060+00:00, run_duration=0.741428, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1243, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-19 21:00:45.716468+00:00, queued_by_job_id=1203, pid=45038[0m
[[34m2023-11-19 21:00:47,590[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 21:00:47,598[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 21:00:48,135[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task scheduled__2023-11-19T20:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 21:00:48,136[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T20:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 21:00:49,711[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:49,711[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 21:00:49,711[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T20:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 21:00:49,712[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='scheduled__2023-11-19T20:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-19 21:00:49,713[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:49,719[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T20:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 21:00:49,723[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=scheduled__2023-11-19T20:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 21:00:49,723[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=scheduled__2023-11-19T20:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 21:00:49,727[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=scheduled__2023-11-19T20:00:00+00:00, map_index=-1, run_start_date=2023-11-19 21:00:48.205828+00:00, run_end_date=2023-11-19 21:00:48.566520+00:00, run_duration=0.360692, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1245, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 21:00:47.524390+00:00, queued_by_job_id=1203, pid=45065[0m
[[34m2023-11-19 21:00:49,727[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=scheduled__2023-11-19T20:00:00+00:00, map_index=-1, run_start_date=2023-11-19 21:00:48.205376+00:00, run_end_date=2023-11-19 21:00:48.587652+00:00, run_duration=0.382276, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1244, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 21:00:47.524390+00:00, queued_by_job_id=1203, pid=45066[0m
[[34m2023-11-19 21:00:49,765[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 21:00:50,273[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T20:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 21:00:51,064[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-19 20:00:00+00:00: scheduled__2023-11-19T20:00:00+00:00, state:running, queued_at: 2023-11-19 21:00:00.596127+00:00. externally triggered: False> successful[0m
[[34m2023-11-19 21:00:51,065[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 20:00:00+00:00, run_id=scheduled__2023-11-19T20:00:00+00:00, run_start_date=2023-11-19 21:00:00.620332+00:00, run_end_date=2023-11-19 21:00:51.065170+00:00, run_duration=50.444838, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-11-19 20:00:00+00:00, data_interval_end=2023-11-19 21:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-19 21:00:51,069[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T21:00:00+00:00, run_after=2023-11-19T22:00:00+00:00[0m
[[34m2023-11-19 21:00:51,092[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=scheduled__2023-11-19T20:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 21:00:51,096[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=scheduled__2023-11-19T20:00:00+00:00, map_index=-1, run_start_date=2023-11-19 21:00:50.333604+00:00, run_end_date=2023-11-19 21:00:50.741804+00:00, run_duration=0.4082, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1246, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-19 21:00:49.711677+00:00, queued_by_job_id=1203, pid=45094[0m
[[34m2023-11-19 21:01:15,853[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:06:15,899[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:11:15,972[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:16:16,022[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:21:16,071[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:26:16,128[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:31:16,179[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:36:16,227[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:41:16,246[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:46:16,297[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:51:16,347[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 21:56:16,396[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:00:00,403[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T22:00:00+00:00, run_after=2023-11-19T23:00:00+00:00[0m
[[34m2023-11-19 22:00:00,462[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:00,462[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 22:00:00,463[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 22:00:00,463[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:00,465[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='scheduled__2023-11-19T21:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 22:00:00,465[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:00,465[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='scheduled__2023-11-19T21:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 22:00:00,465[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:00,471[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:00,475[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:00,525[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 22:00:00,533[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 22:00:01,081[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T21:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 22:00:01,081[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T21:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 22:00:02,349[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:02,349[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 22:00:02,349[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:02,351[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='scheduled__2023-11-19T21:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 22:00:02,351[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:02,357[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:02,361[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=scheduled__2023-11-19T21:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 22:00:02,367[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=scheduled__2023-11-19T21:00:00+00:00, map_index=-1, run_start_date=2023-11-19 22:00:01.208824+00:00, run_end_date=2023-11-19 22:00:02.158091+00:00, run_duration=0.949267, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1247, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 22:00:00.463691+00:00, queued_by_job_id=1203, pid=47245[0m
[[34m2023-11-19 22:00:02,477[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 22:00:03,046[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T21:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 22:00:03,621[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=scheduled__2023-11-19T21:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 22:00:03,628[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=scheduled__2023-11-19T21:00:00+00:00, map_index=-1, run_start_date=2023-11-19 22:00:03.111992+00:00, run_end_date=2023-11-19 22:00:03.418371+00:00, run_duration=0.306379, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1249, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 22:00:02.350023+00:00, queued_by_job_id=1203, pid=47367[0m
[[34m2023-11-19 22:00:43,054[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:43,055[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 22:00:43,055[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:43,064[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='scheduled__2023-11-19T21:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 22:00:43,065[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:43,073[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:43,075[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=scheduled__2023-11-19T21:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 22:00:43,080[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=scheduled__2023-11-19T21:00:00+00:00, map_index=-1, run_start_date=2023-11-19 22:00:01.194999+00:00, run_end_date=2023-11-19 22:00:42.286471+00:00, run_duration=41.091472, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1248, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 22:00:00.463691+00:00, queued_by_job_id=1203, pid=47244[0m
[[34m2023-11-19 22:00:43,123[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 22:00:43,662[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T21:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 22:00:45,272[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:45,272[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 22:00:45,272[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:45,275[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='scheduled__2023-11-19T21:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-19 22:00:45,278[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:45,285[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:45,287[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=scheduled__2023-11-19T21:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 22:00:45,292[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=scheduled__2023-11-19T21:00:00+00:00, map_index=-1, run_start_date=2023-11-19 22:00:43.724588+00:00, run_end_date=2023-11-19 22:00:44.088493+00:00, run_duration=0.363905, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1250, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 22:00:43.055664+00:00, queued_by_job_id=1203, pid=47434[0m
[[34m2023-11-19 22:00:45,333[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 22:00:45,829[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T21:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 22:00:47,022[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:47,023[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 22:00:47,023[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 22:00:47,023[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:47,025[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='scheduled__2023-11-19T21:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 22:00:47,025[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:47,025[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='scheduled__2023-11-19T21:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 22:00:47,025[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:47,032[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:47,035[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=scheduled__2023-11-19T21:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 22:00:47,035[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:47,042[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=scheduled__2023-11-19T21:00:00+00:00, map_index=-1, run_start_date=2023-11-19 22:00:45.890489+00:00, run_end_date=2023-11-19 22:00:46.581622+00:00, run_duration=0.691133, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1251, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-19 22:00:45.273024+00:00, queued_by_job_id=1203, pid=47452[0m
[[34m2023-11-19 22:00:47,085[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 22:00:47,105[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 22:00:47,643[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task scheduled__2023-11-19T21:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 22:00:47,653[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T21:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 22:00:48,185[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:48,185[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 22:00:48,185[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T21:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 22:00:48,188[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='scheduled__2023-11-19T21:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-19 22:00:48,188[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:48,198[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T21:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 22:00:48,295[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 22:00:48,311[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=scheduled__2023-11-19T21:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 22:00:48,311[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=scheduled__2023-11-19T21:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 22:00:48,315[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=scheduled__2023-11-19T21:00:00+00:00, map_index=-1, run_start_date=2023-11-19 22:00:47.710696+00:00, run_end_date=2023-11-19 22:00:48.090026+00:00, run_duration=0.37933, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1252, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 22:00:47.023658+00:00, queued_by_job_id=1203, pid=47479[0m
[[34m2023-11-19 22:00:48,316[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=scheduled__2023-11-19T21:00:00+00:00, map_index=-1, run_start_date=2023-11-19 22:00:47.714041+00:00, run_end_date=2023-11-19 22:00:48.070154+00:00, run_duration=0.356113, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1253, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 22:00:47.023658+00:00, queued_by_job_id=1203, pid=47480[0m
[[34m2023-11-19 22:00:48,833[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T21:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 22:00:50,295[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-19 21:00:00+00:00: scheduled__2023-11-19T21:00:00+00:00, state:running, queued_at: 2023-11-19 22:00:00.394493+00:00. externally triggered: False> successful[0m
[[34m2023-11-19 22:00:50,296[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 21:00:00+00:00, run_id=scheduled__2023-11-19T21:00:00+00:00, run_start_date=2023-11-19 22:00:00.420674+00:00, run_end_date=2023-11-19 22:00:50.295983+00:00, run_duration=49.875309, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-11-19 21:00:00+00:00, data_interval_end=2023-11-19 22:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-19 22:00:50,300[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T22:00:00+00:00, run_after=2023-11-19T23:00:00+00:00[0m
[[34m2023-11-19 22:00:50,321[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=scheduled__2023-11-19T21:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 22:00:50,326[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=scheduled__2023-11-19T21:00:00+00:00, map_index=-1, run_start_date=2023-11-19 22:00:48.888668+00:00, run_end_date=2023-11-19 22:00:49.379193+00:00, run_duration=0.490525, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1254, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-19 22:00:48.186345+00:00, queued_by_job_id=1203, pid=47510[0m
[[34m2023-11-19 22:01:16,443[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:06:16,491[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:11:16,583[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:16:16,631[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:21:16,702[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:26:16,752[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:31:16,790[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:36:16,839[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:41:16,887[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:46:16,937[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:51:16,986[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 22:56:17,033[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:00:00,789[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T23:00:00+00:00, run_after=2023-11-20T00:00:00+00:00[0m
[[34m2023-11-19 23:00:00,864[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:00,865[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 23:00:00,865[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 23:00:00,865[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:00,867[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='scheduled__2023-11-19T22:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 23:00:00,867[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:00,867[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='scheduled__2023-11-19T22:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-19 23:00:00,867[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:00,874[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:00,875[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:00,923[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 23:00:00,925[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 23:00:01,478[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T22:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 23:00:01,488[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T22:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 23:00:03,129[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:03,129[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 23:00:03,129[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:03,131[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='scheduled__2023-11-19T22:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 23:00:03,131[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:03,145[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:03,147[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=scheduled__2023-11-19T22:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 23:00:03,152[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=scheduled__2023-11-19T22:00:00+00:00, map_index=-1, run_start_date=2023-11-19 23:00:01.548820+00:00, run_end_date=2023-11-19 23:00:02.368950+00:00, run_duration=0.82013, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1255, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 23:00:00.865650+00:00, queued_by_job_id=1203, pid=50362[0m
[[34m2023-11-19 23:00:03,191[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 23:00:03,767[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T22:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 23:00:05,083[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=scheduled__2023-11-19T22:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 23:00:05,088[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=scheduled__2023-11-19T22:00:00+00:00, map_index=-1, run_start_date=2023-11-19 23:00:03.838183+00:00, run_end_date=2023-11-19 23:00:04.250370+00:00, run_duration=0.412187, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1257, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 23:00:03.130181+00:00, queued_by_job_id=1203, pid=50484[0m
[[34m2023-11-19 23:00:43,678[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:43,678[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 23:00:43,678[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:43,680[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='scheduled__2023-11-19T22:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-19 23:00:43,680[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:43,686[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:43,687[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=scheduled__2023-11-19T22:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 23:00:43,690[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=scheduled__2023-11-19T22:00:00+00:00, map_index=-1, run_start_date=2023-11-19 23:00:01.555929+00:00, run_end_date=2023-11-19 23:00:42.782538+00:00, run_duration=41.226609, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1256, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-19 23:00:00.865650+00:00, queued_by_job_id=1203, pid=50363[0m
[[34m2023-11-19 23:00:43,732[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 23:00:44,258[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T22:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 23:00:45,381[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:45,381[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 23:00:45,381[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:45,383[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='scheduled__2023-11-19T22:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-19 23:00:45,383[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:45,390[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:45,391[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=scheduled__2023-11-19T22:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 23:00:45,398[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=scheduled__2023-11-19T22:00:00+00:00, map_index=-1, run_start_date=2023-11-19 23:00:44.321706+00:00, run_end_date=2023-11-19 23:00:44.683972+00:00, run_duration=0.362266, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1258, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-19 23:00:43.678782+00:00, queued_by_job_id=1203, pid=50564[0m
[[34m2023-11-19 23:00:45,441[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 23:00:45,983[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T22:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 23:00:47,297[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:47,297[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 23:00:47,297[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-19 23:00:47,297[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:47,299[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='scheduled__2023-11-19T22:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 23:00:47,299[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:47,299[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='scheduled__2023-11-19T22:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-19 23:00:47,300[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:47,307[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:47,311[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:47,311[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=scheduled__2023-11-19T22:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 23:00:47,315[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=scheduled__2023-11-19T22:00:00+00:00, map_index=-1, run_start_date=2023-11-19 23:00:46.046154+00:00, run_end_date=2023-11-19 23:00:46.747966+00:00, run_duration=0.701812, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1259, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-19 23:00:45.382146+00:00, queued_by_job_id=1203, pid=50584[0m
[[34m2023-11-19 23:00:47,361[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 23:00:47,368[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 23:00:48,106[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T22:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 23:00:48,326[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task scheduled__2023-11-19T22:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 23:00:49,570[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:49,570[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-19 23:00:49,571[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T22:00:00+00:00 [scheduled]>[0m
[[34m2023-11-19 23:00:49,572[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='scheduled__2023-11-19T22:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-19 23:00:49,572[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:49,579[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T22:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-19 23:00:49,584[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=scheduled__2023-11-19T22:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 23:00:49,585[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=scheduled__2023-11-19T22:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 23:00:49,588[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=scheduled__2023-11-19T22:00:00+00:00, map_index=-1, run_start_date=2023-11-19 23:00:48.205874+00:00, run_end_date=2023-11-19 23:00:48.580373+00:00, run_duration=0.374499, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1260, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 23:00:47.298105+00:00, queued_by_job_id=1203, pid=50609[0m
[[34m2023-11-19 23:00:49,588[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=scheduled__2023-11-19T22:00:00+00:00, map_index=-1, run_start_date=2023-11-19 23:00:48.419601+00:00, run_end_date=2023-11-19 23:00:48.817061+00:00, run_duration=0.39746, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1261, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-19 23:00:47.298105+00:00, queued_by_job_id=1203, pid=50620[0m
[[34m2023-11-19 23:00:49,648[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-19 23:00:50,184[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T22:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-19 23:00:51,736[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-19 22:00:00+00:00: scheduled__2023-11-19T22:00:00+00:00, state:running, queued_at: 2023-11-19 23:00:00.781749+00:00. externally triggered: False> successful[0m
[[34m2023-11-19 23:00:51,736[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 22:00:00+00:00, run_id=scheduled__2023-11-19T22:00:00+00:00, run_start_date=2023-11-19 23:00:00.829331+00:00, run_end_date=2023-11-19 23:00:51.736724+00:00, run_duration=50.907393, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-11-19 22:00:00+00:00, data_interval_end=2023-11-19 23:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-19 23:00:51,740[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-19T23:00:00+00:00, run_after=2023-11-20T00:00:00+00:00[0m
[[34m2023-11-19 23:00:51,788[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=scheduled__2023-11-19T22:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-19 23:00:51,793[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=scheduled__2023-11-19T22:00:00+00:00, map_index=-1, run_start_date=2023-11-19 23:00:50.240365+00:00, run_end_date=2023-11-19 23:00:50.732794+00:00, run_duration=0.492429, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1262, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-19 23:00:49.571430+00:00, queued_by_job_id=1203, pid=50648[0m
[[34m2023-11-19 23:01:17,081[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:06:17,132[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:11:17,194[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:16:17,244[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:21:17,294[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:26:17,342[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:31:17,392[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:36:17,439[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:41:17,497[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:46:17,550[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:51:17,598[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-19 23:56:17,645[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:00:00,024[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-20T00:00:00+00:00, run_after=2023-11-20T01:00:00+00:00[0m
[[34m2023-11-20 00:00:00,230[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:00,231[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 00:00:00,231[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 00:00:00,231[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:00,233[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='scheduled__2023-11-19T23:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-20 00:00:00,233[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:00,234[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='scheduled__2023-11-19T23:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-20 00:00:00,234[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:00,241[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:00,243[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:00,303[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 00:00:00,341[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 00:00:00,883[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-19T23:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 00:00:00,901[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task scheduled__2023-11-19T23:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 00:00:02,659[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:02,659[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 00:00:02,659[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:02,662[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='scheduled__2023-11-19T23:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-20 00:00:02,662[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:02,712[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:02,713[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=scheduled__2023-11-19T23:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 00:00:02,723[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=scheduled__2023-11-19T23:00:00+00:00, map_index=-1, run_start_date=2023-11-20 00:00:00.952774+00:00, run_end_date=2023-11-20 00:00:01.846585+00:00, run_duration=0.893811, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1263, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-20 00:00:00.232018+00:00, queued_by_job_id=1203, pid=52829[0m
[[34m2023-11-20 00:00:02,855[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 00:00:03,429[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task scheduled__2023-11-19T23:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 00:00:06,356[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=scheduled__2023-11-19T23:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 00:00:06,361[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=scheduled__2023-11-19T23:00:00+00:00, map_index=-1, run_start_date=2023-11-20 00:00:03.747313+00:00, run_end_date=2023-11-20 00:00:04.755078+00:00, run_duration=1.007765, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1265, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-20 00:00:02.660455+00:00, queued_by_job_id=1203, pid=52885[0m
[[34m2023-11-20 00:00:48,428[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:48,428[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 00:00:48,428[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:48,430[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='scheduled__2023-11-19T23:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-20 00:00:48,430[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:48,437[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:48,439[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=scheduled__2023-11-19T23:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 00:00:48,445[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=scheduled__2023-11-19T23:00:00+00:00, map_index=-1, run_start_date=2023-11-20 00:00:00.972662+00:00, run_end_date=2023-11-20 00:00:47.840183+00:00, run_duration=46.867521, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1264, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-20 00:00:00.232018+00:00, queued_by_job_id=1203, pid=52831[0m
[[34m2023-11-20 00:00:48,479[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 00:00:49,003[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task scheduled__2023-11-19T23:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 00:00:49,578[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:49,578[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 00:00:49,578[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:49,580[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='scheduled__2023-11-19T23:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-20 00:00:49,580[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:49,589[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:49,648[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=scheduled__2023-11-19T23:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 00:00:49,653[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=scheduled__2023-11-19T23:00:00+00:00, map_index=-1, run_start_date=2023-11-20 00:00:49.079818+00:00, run_end_date=2023-11-20 00:00:49.450017+00:00, run_duration=0.370199, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1266, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-20 00:00:48.429107+00:00, queued_by_job_id=1203, pid=53043[0m
[[34m2023-11-20 00:00:49,659[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 00:00:50,184[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-19T23:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 00:00:51,379[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:51,379[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 00:00:51,379[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 00:00:51,379[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:51,381[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='scheduled__2023-11-19T23:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-20 00:00:51,381[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:51,381[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='scheduled__2023-11-19T23:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-20 00:00:51,382[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:51,388[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:51,390[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:51,394[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=scheduled__2023-11-19T23:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 00:00:51,398[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=scheduled__2023-11-19T23:00:00+00:00, map_index=-1, run_start_date=2023-11-20 00:00:50.253263+00:00, run_end_date=2023-11-20 00:00:50.931171+00:00, run_duration=0.677908, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1267, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-20 00:00:49.579235+00:00, queued_by_job_id=1203, pid=53061[0m
[[34m2023-11-20 00:00:51,437[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 00:00:51,447[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 00:00:52,009[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task scheduled__2023-11-19T23:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 00:00:52,033[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task scheduled__2023-11-19T23:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 00:00:52,996[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:52,996[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 00:00:52,996[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T23:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 00:00:52,998[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='scheduled__2023-11-19T23:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-20 00:00:52,998[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:53,005[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-19T23:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 00:00:53,019[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=scheduled__2023-11-19T23:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 00:00:53,019[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=scheduled__2023-11-19T23:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 00:00:53,025[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=scheduled__2023-11-19T23:00:00+00:00, map_index=-1, run_start_date=2023-11-20 00:00:52.077403+00:00, run_end_date=2023-11-20 00:00:52.421589+00:00, run_duration=0.344186, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1268, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-20 00:00:51.379893+00:00, queued_by_job_id=1203, pid=53088[0m
[[34m2023-11-20 00:00:53,025[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=scheduled__2023-11-19T23:00:00+00:00, map_index=-1, run_start_date=2023-11-20 00:00:52.098150+00:00, run_end_date=2023-11-20 00:00:52.450998+00:00, run_duration=0.352848, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1269, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-20 00:00:51.379893+00:00, queued_by_job_id=1203, pid=53090[0m
[[34m2023-11-20 00:00:53,076[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 00:00:53,637[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-19T23:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 00:00:55,209[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-19 23:00:00+00:00: scheduled__2023-11-19T23:00:00+00:00, state:running, queued_at: 2023-11-20 00:00:00.013969+00:00. externally triggered: False> successful[0m
[[34m2023-11-20 00:00:55,210[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-19 23:00:00+00:00, run_id=scheduled__2023-11-19T23:00:00+00:00, run_start_date=2023-11-20 00:00:00.117094+00:00, run_end_date=2023-11-20 00:00:55.210073+00:00, run_duration=55.092979, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-11-19 23:00:00+00:00, data_interval_end=2023-11-20 00:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-20 00:00:55,214[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-20T00:00:00+00:00, run_after=2023-11-20T01:00:00+00:00[0m
[[34m2023-11-20 00:00:55,244[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=scheduled__2023-11-19T23:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 00:00:55,248[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=scheduled__2023-11-19T23:00:00+00:00, map_index=-1, run_start_date=2023-11-20 00:00:53.706531+00:00, run_end_date=2023-11-20 00:00:54.127899+00:00, run_duration=0.421368, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1270, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-20 00:00:52.996693+00:00, queued_by_job_id=1203, pid=53120[0m
[[34m2023-11-20 00:01:17,696[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:06:17,743[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:11:17,808[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:16:17,858[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:21:17,905[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:26:17,953[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:31:18,007[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:36:18,054[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:41:18,118[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:46:18,169[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:51:18,224[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 00:56:18,274[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 01:00:00,237[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-20T01:00:00+00:00, run_after=2023-11-20T02:00:00+00:00[0m
[[34m2023-11-20 01:00:00,345[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:00,346[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:00:00,346[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 01:00:00,346[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:00,348[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='scheduled__2023-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-20 01:00:00,348[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:00,348[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='scheduled__2023-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-20 01:00:00,349[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:00,362[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:00,363[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:00,415[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:00:00,422[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:00:00,985[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task scheduled__2023-11-20T00:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:00:01,098[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task scheduled__2023-11-20T00:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:00:02,906[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:02,906[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 01:00:02,906[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:02,908[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='scheduled__2023-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-20 01:00:02,908[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:02,924[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:02,928[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=scheduled__2023-11-20T00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:00:02,934[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=scheduled__2023-11-20T00:00:00+00:00, map_index=-1, run_start_date=2023-11-20 01:00:01.086246+00:00, run_end_date=2023-11-20 01:00:02.107238+00:00, run_duration=1.020992, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1271, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-20 01:00:00.347030+00:00, queued_by_job_id=1203, pid=55411[0m
[[34m2023-11-20 01:00:02,971[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:00:03,564[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task scheduled__2023-11-20T00:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:00:05,156[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=scheduled__2023-11-20T00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:00:05,161[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=scheduled__2023-11-20T00:00:00+00:00, map_index=-1, run_start_date=2023-11-20 01:00:03.651564+00:00, run_end_date=2023-11-20 01:00:03.999720+00:00, run_duration=0.348156, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1273, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-20 01:00:02.907022+00:00, queued_by_job_id=1203, pid=55533[0m
[[34m2023-11-20 01:00:43,654[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:43,654[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:00:43,654[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:43,656[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='scheduled__2023-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-20 01:00:43,656[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:43,663[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:43,667[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=scheduled__2023-11-20T00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:00:43,671[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=scheduled__2023-11-20T00:00:00+00:00, map_index=-1, run_start_date=2023-11-20 01:00:01.193321+00:00, run_end_date=2023-11-20 01:00:43.205608+00:00, run_duration=42.012287, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1272, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-20 01:00:00.347030+00:00, queued_by_job_id=1203, pid=55414[0m
[[34m2023-11-20 01:00:43,713[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:00:44,223[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task scheduled__2023-11-20T00:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:00:44,802[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:44,802[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:00:44,802[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:44,804[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='scheduled__2023-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-20 01:00:44,804[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:44,812[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:44,858[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:00:44,886[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=scheduled__2023-11-20T00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:00:44,890[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=scheduled__2023-11-20T00:00:00+00:00, map_index=-1, run_start_date=2023-11-20 01:00:44.290423+00:00, run_end_date=2023-11-20 01:00:44.666299+00:00, run_duration=0.375876, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1274, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-20 01:00:43.655188+00:00, queued_by_job_id=1203, pid=55616[0m
[[34m2023-11-20 01:00:45,383[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task scheduled__2023-11-20T00:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:00:47,204[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:47,204[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:00:47,204[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 01:00:47,204[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:47,206[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='scheduled__2023-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-20 01:00:47,206[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:47,206[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='scheduled__2023-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-20 01:00:47,206[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:47,214[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:47,215[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=scheduled__2023-11-20T00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:00:47,216[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:47,229[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=scheduled__2023-11-20T00:00:00+00:00, map_index=-1, run_start_date=2023-11-20 01:00:45.443222+00:00, run_end_date=2023-11-20 01:00:46.146726+00:00, run_duration=0.703504, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1275, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-20 01:00:44.802934+00:00, queued_by_job_id=1203, pid=55634[0m
[[34m2023-11-20 01:00:47,263[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:00:47,275[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:00:47,833[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task scheduled__2023-11-20T00:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:00:47,836[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task scheduled__2023-11-20T00:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:00:48,345[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:48,345[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:00:48,345[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-20T00:00:00+00:00 [scheduled]>[0m
[[34m2023-11-20 01:00:48,347[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='scheduled__2023-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-20 01:00:48,347[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:48,363[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'scheduled__2023-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:00:48,422[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:00:48,439[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=scheduled__2023-11-20T00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:00:48,439[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=scheduled__2023-11-20T00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:00:48,447[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=scheduled__2023-11-20T00:00:00+00:00, map_index=-1, run_start_date=2023-11-20 01:00:47.909017+00:00, run_end_date=2023-11-20 01:00:48.212282+00:00, run_duration=0.303265, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1277, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-20 01:00:47.205017+00:00, queued_by_job_id=1203, pid=55663[0m
[[34m2023-11-20 01:00:48,448[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=scheduled__2023-11-20T00:00:00+00:00, map_index=-1, run_start_date=2023-11-20 01:00:47.893348+00:00, run_end_date=2023-11-20 01:00:48.256729+00:00, run_duration=0.363381, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1276, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-20 01:00:47.205017+00:00, queued_by_job_id=1203, pid=55662[0m
[[34m2023-11-20 01:00:49,008[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task scheduled__2023-11-20T00:00:00+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:00:50,555[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-20 00:00:00+00:00: scheduled__2023-11-20T00:00:00+00:00, state:running, queued_at: 2023-11-20 01:00:00.228380+00:00. externally triggered: False> successful[0m
[[34m2023-11-20 01:00:50,555[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-20 00:00:00+00:00, run_id=scheduled__2023-11-20T00:00:00+00:00, run_start_date=2023-11-20 01:00:00.298726+00:00, run_end_date=2023-11-20 01:00:50.555297+00:00, run_duration=50.256571, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-11-20 00:00:00+00:00, data_interval_end=2023-11-20 01:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-20 01:00:50,559[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-20T01:00:00+00:00, run_after=2023-11-20T02:00:00+00:00[0m
[[34m2023-11-20 01:00:50,580[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=scheduled__2023-11-20T00:00:00+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:00:50,584[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=scheduled__2023-11-20T00:00:00+00:00, map_index=-1, run_start_date=2023-11-20 01:00:49.075216+00:00, run_end_date=2023-11-20 01:00:49.505280+00:00, run_duration=0.430064, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1278, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-20 01:00:48.345946+00:00, queued_by_job_id=1203, pid=55691[0m
[[34m2023-11-20 01:01:18,170[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:01:18,170[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:01:18,170[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 01:01:18,171[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>
	<TaskInstance: party_animals.scrape_review_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:01:18,172[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='fetch_chart_data_task', run_id='manual__2023-11-20T01:01:17.887435+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-20 01:01:18,173[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:01:18,173[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='scrape_review_task', run_id='manual__2023-11-20T01:01:17.887435+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2023-11-20 01:01:18,173[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:01:18,181[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'fetch_chart_data_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:01:18,183[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'scrape_review_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:01:18,226[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:01:18,240[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:01:18,311[0m] {[34mscheduler_job.py:[0m1399} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-11-20 01:01:19,098[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.fetch_chart_data_task manual__2023-11-20T01:01:17.887435+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:01:19,214[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.scrape_review_task manual__2023-11-20T01:01:17.887435+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:01:20,511[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_chart_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:01:20,511[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 01:01:20,512[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_chart_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:01:20,518[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_chart_task', run_id='manual__2023-11-20T01:01:17.887435+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-20 01:01:20,518[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:01:20,529[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_chart_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:01:20,531[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.fetch_chart_data_task run_id=manual__2023-11-20T01:01:17.887435+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:01:20,536[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=fetch_chart_data_task, run_id=manual__2023-11-20T01:01:17.887435+00:00, map_index=-1, run_start_date=2023-11-20 01:01:19.218173+00:00, run_end_date=2023-11-20 01:01:19.932838+00:00, run_duration=0.714665, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1279, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-20 01:01:18.171494+00:00, queued_by_job_id=1203, pid=55743[0m
[[34m2023-11-20 01:01:20,582[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:01:21,121[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_chart_task manual__2023-11-20T01:01:17.887435+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:01:22,120[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_chart_task run_id=manual__2023-11-20T01:01:17.887435+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:01:22,127[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_chart_task, run_id=manual__2023-11-20T01:01:17.887435+00:00, map_index=-1, run_start_date=2023-11-20 01:01:21.182060+00:00, run_end_date=2023-11-20 01:01:21.733408+00:00, run_duration=0.551348, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1281, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-20 01:01:20.512649+00:00, queued_by_job_id=1203, pid=55861[0m
[[34m2023-11-20 01:02:02,199[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.transform_review_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:02:02,200[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:02:02,200[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.transform_review_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:02:02,201[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='transform_review_task', run_id='manual__2023-11-20T01:01:17.887435+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2023-11-20 01:02:02,202[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:02,209[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'transform_review_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:02,211[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.scrape_review_task run_id=manual__2023-11-20T01:01:17.887435+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:02:02,215[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=scrape_review_task, run_id=manual__2023-11-20T01:01:17.887435+00:00, map_index=-1, run_start_date=2023-11-20 01:01:19.296916+00:00, run_end_date=2023-11-20 01:02:01.424803+00:00, run_duration=42.127887, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1280, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2023-11-20 01:01:18.171494+00:00, queued_by_job_id=1203, pid=55746[0m
[[34m2023-11-20 01:02:02,258[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:02:02,801[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.transform_review_task manual__2023-11-20T01:01:17.887435+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:02:04,053[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_raw_data_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:02:04,053[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:02:04,053[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_raw_data_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:02:04,063[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_raw_data_task', run_id='manual__2023-11-20T01:01:17.887435+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2023-11-20 01:02:04,063[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:04,071[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_raw_data_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:04,075[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.transform_review_task run_id=manual__2023-11-20T01:01:17.887435+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:02:04,080[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=transform_review_task, run_id=manual__2023-11-20T01:01:17.887435+00:00, map_index=-1, run_start_date=2023-11-20 01:02:02.860894+00:00, run_end_date=2023-11-20 01:02:03.260371+00:00, run_duration=0.399477, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1282, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2023-11-20 01:02:02.200575+00:00, queued_by_job_id=1203, pid=55929[0m
[[34m2023-11-20 01:02:04,147[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:02:04,742[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_raw_data_task manual__2023-11-20T01:01:17.887435+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:02:06,323[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 2 tasks up for execution:
	<TaskInstance: party_animals.group_chart_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:02:06,324[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:02:06,324[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 1/16 running and queued tasks[0m
[[34m2023-11-20 01:02:06,324[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.group_chart_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>
	<TaskInstance: party_animals.group_review_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:02:06,326[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_chart_task', run_id='manual__2023-11-20T01:01:17.887435+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-20 01:02:06,326[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:06,326[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='group_review_task', run_id='manual__2023-11-20T01:01:17.887435+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-11-20 01:02:06,326[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:06,337[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_chart_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:06,339[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'group_review_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:06,343[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_raw_data_task run_id=manual__2023-11-20T01:01:17.887435+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:02:06,355[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_raw_data_task, run_id=manual__2023-11-20T01:01:17.887435+00:00, map_index=-1, run_start_date=2023-11-20 01:02:04.801537+00:00, run_end_date=2023-11-20 01:02:05.548215+00:00, run_duration=0.746678, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1283, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2023-11-20 01:02:04.053929+00:00, queued_by_job_id=1203, pid=55954[0m
[[34m2023-11-20 01:02:06,392[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:02:06,384[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:02:07,079[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_chart_task manual__2023-11-20T01:01:17.887435+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:02:07,164[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.group_review_task manual__2023-11-20T01:01:17.887435+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:02:08,032[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: party_animals.insert_combined_data_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:02:08,032[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG party_animals has 0/16 running and queued tasks[0m
[[34m2023-11-20 01:02:08,033[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: party_animals.insert_combined_data_task manual__2023-11-20T01:01:17.887435+00:00 [scheduled]>[0m
[[34m2023-11-20 01:02:08,035[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='party_animals', task_id='insert_combined_data_task', run_id='manual__2023-11-20T01:01:17.887435+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-11-20 01:02:08,035[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:08,056[0m] {[34mlocal_executor.py:[0m81} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'party_animals', 'insert_combined_data_task', 'manual__2023-11-20T01:01:17.887435+00:00', '--local', '--subdir', 'DAGS_FOLDER/party_animals_dag.py'][0m
[[34m2023-11-20 01:02:08,058[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_chart_task run_id=manual__2023-11-20T01:01:17.887435+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:02:08,058[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.group_review_task run_id=manual__2023-11-20T01:01:17.887435+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:02:08,064[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_chart_task, run_id=manual__2023-11-20T01:01:17.887435+00:00, map_index=-1, run_start_date=2023-11-20 01:02:07.163972+00:00, run_end_date=2023-11-20 01:02:07.483041+00:00, run_duration=0.319069, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1284, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-20 01:02:06.324848+00:00, queued_by_job_id=1203, pid=55983[0m
[[34m2023-11-20 01:02:08,064[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=group_review_task, run_id=manual__2023-11-20T01:01:17.887435+00:00, map_index=-1, run_start_date=2023-11-20 01:02:07.254283+00:00, run_end_date=2023-11-20 01:02:07.630724+00:00, run_duration=0.376441, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1285, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-11-20 01:02:06.324848+00:00, queued_by_job_id=1203, pid=55987[0m
[[34m2023-11-20 01:02:08,115[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/rekayasadata/rekdat/dags/party_animals_dag.py[0m
[[34m2023-11-20 01:02:08,687[0m] {[34mtask_command.py:[0m389} INFO[0m - Running <TaskInstance: party_animals.insert_combined_data_task manual__2023-11-20T01:01:17.887435+00:00 [queued]> on host rekayasa-data.4ewe5rigcbguncbquzfmoh3tef.ix.internal.cloudapp.net[0m
[[34m2023-11-20 01:02:10,293[0m] {[34mdagrun.py:[0m606} INFO[0m - Marking run <DagRun party_animals @ 2023-11-20 01:01:17.887435+00:00: manual__2023-11-20T01:01:17.887435+00:00, state:running, queued_at: 2023-11-20 01:01:17.897492+00:00. externally triggered: True> successful[0m
[[34m2023-11-20 01:02:10,293[0m] {[34mdagrun.py:[0m657} INFO[0m - DagRun Finished: dag_id=party_animals, execution_date=2023-11-20 01:01:17.887435+00:00, run_id=manual__2023-11-20T01:01:17.887435+00:00, run_start_date=2023-11-20 01:01:18.124887+00:00, run_end_date=2023-11-20 01:02:10.293622+00:00, run_duration=52.168735, state=success, external_trigger=True, run_type=manual, data_interval_start=2023-11-20 00:00:00+00:00, data_interval_end=2023-11-20 01:00:00+00:00, dag_hash=b10c6470610ee7c9103b8cb57adae089[0m
[[34m2023-11-20 01:02:10,297[0m] {[34mdag.py:[0m3423} INFO[0m - Setting next_dagrun for party_animals to 2023-11-20T01:00:00+00:00, run_after=2023-11-20T02:00:00+00:00[0m
[[34m2023-11-20 01:02:10,320[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of party_animals.insert_combined_data_task run_id=manual__2023-11-20T01:01:17.887435+00:00 exited with status success for try_number 1[0m
[[34m2023-11-20 01:02:10,325[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=party_animals, task_id=insert_combined_data_task, run_id=manual__2023-11-20T01:01:17.887435+00:00, map_index=-1, run_start_date=2023-11-20 01:02:08.743677+00:00, run_end_date=2023-11-20 01:02:09.231155+00:00, run_duration=0.487478, state=success, executor_state=success, try_number=1, max_tries=0, job_id=1286, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-11-20 01:02:08.033468+00:00, queued_by_job_id=1203, pid=56020[0m
